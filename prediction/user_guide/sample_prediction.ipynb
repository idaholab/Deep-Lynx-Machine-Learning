{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d9c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021, Battelle Energy Alliance, LLC\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Change working directory if not the project directory\n",
    "current_dir = os.getcwd()\n",
    "folders = re.split('\\/', current_dir)\n",
    "if folders[len(folders)-1] == 'prediction':\n",
    "    os.chdir(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "# Load environment variables from .env file    \n",
    "!pip install python-dotenv\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "import settings\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa85c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getenv(\"ML_ADAPTER_OBJECT_LOCATION\"), 'r') as fp:\n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1011aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \"\"\"\n",
    "    Load the model from disk\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    filename = data[\"MODEL\"][\"model_serialization_file\"]\n",
    "    loaded_model = pickle.load(open(filename, 'rb'))\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac7cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_mean_normalization(data, X_train_mean, X_train_std):\n",
    "    \"\"\"\n",
    "    Standardizes the data according to the z-score formula \n",
    "    z = (x – μ) / σ \n",
    "    \n",
    "    Note: Only the training mean and standard deviation are used for the standardization of the data.\n",
    "    This ensures that there is no contamination of the test data set.\n",
    "    \"\"\"\n",
    "    standardize_data = (data - X_train_mean) / X_train_std\n",
    "    return standardize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67657da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, data):\n",
    "    \"\"\"\n",
    "    Use an existing model to make a prediction with the incoming data\n",
    "    \"\"\"\n",
    "    yhat = model.predict(data)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstandardize_mean_normalization(yhat, y_train_mean, y_train_std):\n",
    "    \"\"\"\n",
    "    Unstandardizes the data according to the z-score formula \n",
    "    z = (x * σ) + μ\n",
    "    \n",
    "    Note: Only the training mean and standard deviation are used for the standardization of the data.\n",
    "    This ensures that there is no contamination of the test data set.\n",
    "    \"\"\"\n",
    "    yhat = (yhat * y_train_std) + y_train_mean\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35270f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_JSON_file(yhat, independent_variables, dependent_variables, tolerance=2):\n",
    "    \"\"\"\n",
    "    Create a .json file of the machine learning results\n",
    "    \"\"\"\n",
    "    # Create a dictionary of the machine learning results\n",
    "    json_data = dict()\n",
    "    json_data[\"Independent Variables\"] = independent_variables\n",
    "    json_data[\"Dependent Variables\"] = dependent_variables\n",
    "    json_data[\"Fitted\"] = {}\n",
    "    json_data[\"Fitted\"][\"test\"] = yhat.round(tolerance).tolist()\n",
    "    \n",
    "    # Write the data to a JSON File\n",
    "    location = data[\"PREDICTION\"][\"output_file\"]\n",
    "    with open(location, \"w\") as f:\n",
    "        json.dump(json_data, f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c77295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction():\n",
    "    # Retrieve Data\n",
    "    test_data = pd.read_csv('data/test.csv')\n",
    "    \n",
    "    # Load the model from a file\n",
    "    model = load_model()\n",
    "    \n",
    "    # Read standardization input file\n",
    "    with open(data[\"PREDICTION\"][\"input_file\"], 'r') as fp:\n",
    "        model_info = json.load(fp)\n",
    "    \n",
    "    # Set standardization values\n",
    "    X_train_mean = model_info['data']['mean']['X_train']\n",
    "    X_train_std = model_info['data']['std']['X_train']\n",
    "    y_train_mean = model_info['data']['mean']['y_train']\n",
    "    y_train_std = model_info['data']['std']['y_train']\n",
    "    \n",
    "    # Standardize the data\n",
    "    test_data = standardize_mean_normalization(test_data, X_train_mean, X_train_std)\n",
    "    \n",
    "    # Make a prediction with the incoming data\n",
    "    yhat = prediction(model, test_data)\n",
    "    \n",
    "    # Unstandardize the data\n",
    "    yhat = unstandardize_mean_normalization(yhat, y_train_mean, y_train_std)\n",
    "    \n",
    "    # Generate JSON file of results\n",
    "    create_JSON_file(yhat, test_time, tolerance=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1232347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_prediction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
