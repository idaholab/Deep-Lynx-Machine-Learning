{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Copyright 2021, Battelle Energy Alliance, LLC\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "!pip install pygam\n",
    "\n",
    "# Change working directory if not the project directory\n",
    "current_dir = os.getcwd()\n",
    "folders = re.split('\\/', current_dir)\n",
    "if folders[len(folders)-1] == 'model':\n",
    "    os.chdir(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "# Load environment variables from .env file    \n",
    "!pip install python-dotenv\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "import settings\n",
    "%pwd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open(os.getenv(\"ML_ADAPTER_OBJECT_LOCATION\"), 'r') as fp:\n",
    "    data = json.load(fp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def standardize_mean_normalization(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Standardizes the data according to the z-score formula\n",
    "\n",
    "    z = (x – μ) / σ\n",
    "\n",
    "    Note: Only the training mean and standard deviation are used for the standardization of the data.\n",
    "    This ensures that there is no contamination of the test data set.\n",
    "\n",
    "    Args\n",
    "        X_train (DataFrame): a subset of the Features, X, Predictors dataset used for training\n",
    "        X_test (DataFrame): a subset of the Features, X, Predictors dataset used for testing\n",
    "        y_train (Series): a subset of the Response, y, Label dataset used for training\n",
    "        y_test (Series): a subset of the Response, y, Label dataset used for testing\n",
    "    Return\n",
    "        X_train_standardize (DataFrame): a standardized subset of the Features, X, Predictors dataset used for training\n",
    "        X_test_standardize (DataFrame): a standardized subset of the Features, X, Predictors dataset used for testing\n",
    "        y_train_standardize (Series): a standardized subset of the Response, y, Label dataset used for training\n",
    "        y_test_standardize (Series): a standardized subset of the Response, y, Label dataset used for testing\n",
    "        standardize (dictionary): a dictionary of the mean and standard deviation for un-standardizing data and standardizing incoming data e.g. {mean: {X_train: \"\", y_train: \"\"}, std: {X_train: \"\", y_train: \"\"}}\n",
    "    \"\"\"\n",
    "    # Determine the mean and standard deviation\n",
    "    # If pandas Dataframe\n",
    "    if isinstance(X_train, pd.DataFrame):\n",
    "        X_train_mean = list(X_train.mean())\n",
    "        X_train_std = list(X_train.std())\n",
    "    # If pandas Series\n",
    "    else:\n",
    "        X_train_mean = X_train.mean()\n",
    "        X_train_std = X_train.std()\n",
    "\n",
    "    y_train_mean = y_train.mean()\n",
    "    y_train_std = y_train.std()\n",
    "\n",
    "    # Standardize data\n",
    "    X_train_standardize = (X_train - X_train_mean) / X_train_std\n",
    "    X_test_standardize  = (X_test - X_train_mean) / X_train_std\n",
    "    y_train_standardize  = (y_train - y_train_mean) / y_train_std\n",
    "    y_test_standardize  = (y_test - y_train_mean) / y_train_std\n",
    "\n",
    "    # Create a dictionary of the mean and standard deviation for un-standardizing data and standardizing incoming data\n",
    "    standardize = dict()\n",
    "    standardize[\"mean\"] = dict()\n",
    "    standardize[\"std\"] = dict()\n",
    "    standardize[\"mean\"][\"X_train\"] = X_train_mean\n",
    "    standardize[\"std\"][\"X_train\"] = X_train_std\n",
    "    standardize[\"mean\"][\"y_train\"] = y_train_mean\n",
    "    standardize[\"std\"][\"y_train\"] = y_train_std\n",
    "\n",
    "    return X_train_standardize, X_test_standardize, y_train_standardize, y_test_standardize, standardize"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def create_model(X_train, y_train):\n",
    "    model = None\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_fitted_residuals_RMSE_values(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Determine yhat, residuals, and RMSE of training and testing datasets\"\"\"\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    # Get yhat through prediction\n",
    "    yhat_train = model.predict(X_train)\n",
    "    yhat_test = model.predict(X_test)\n",
    "\n",
    "    # Reshape\n",
    "    y_train = y_train.values.reshape(-1,1)\n",
    "    y_test = y_test.values.reshape(-1,1)\n",
    "\n",
    "    # Get residuals and RMSE\n",
    "    y_train_residuals = y_train - yhat_train\n",
    "    y_test_residuals = y_test - yhat_test\n",
    "    rmse_train= mean_squared_error(y_train, yhat_train, squared=False)\n",
    "    rmse_test= mean_squared_error(y_test, yhat_test, squared=False)\n",
    "\n",
    "    return yhat_train, yhat_test, y_train_residuals, y_test_residuals, rmse_train, rmse_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def unstandardize_mean_normalization(y_train, y_test, yhat_train, yhat_test, standardize):\n",
    "    \"\"\"\n",
    "    Unstandardizes the data according to the z-score formula\n",
    "\n",
    "    z = (x * σ) + μ\n",
    "\n",
    "    Note: Only the training mean and standard deviation are used for the standardization of the data.\n",
    "    This ensures that there is no contamination of the test data set.\n",
    "\n",
    "    Args\n",
    "        y_train (Series): a standardized subset of the Response, y, Label dataset used for training\n",
    "        y_test (Series): a standardized subset of the Response, y, Label dataset used for testing\n",
    "        yhat_train (Series): a standardized estimation of the Response, y, Label for training set\n",
    "        yhat_test (Series): a standardized estimation of the Response, y, Label for testing set\n",
    "        standardize (dictionary): a dictionary of the mean and standard deviation for un-standardizing data and standardizing incoming data e.g. {mean: {X_train: \"\", y_train: \"\"}, std: {X_train: \"\", y_train: \"\"}}\n",
    "    Return\n",
    "        y_train (Series): an unstandardized subset of the Response, y, Label dataset used for training\n",
    "        y_test (Series): an unstandardized subset of the Response, y, Label dataset used for testing\n",
    "        yhat_train (Series): an unstandardized estimation of the Response, y, Label for training set\n",
    "        yhat_test (Series): a unstandardized estimation of the Response, y, Label for testing set\n",
    "        y_train_residuals (Series): the difference between the actual train response and the predicted train response (y_train - yhat_train)\n",
    "        y_test_residuals (Series): the difference between the actual test response and the predicted test response (y_test - yhat_test)\n",
    "\n",
    "    \"\"\"   \n",
    "    # Unstandardize y and yhat for the training and testing datasets\n",
    "    y_train_mean = standardize[\"mean\"][\"y_train\"]\n",
    "    y_train_std = standardize[\"std\"][\"y_train\"]\n",
    "\n",
    "    y_train = (y_train * y_train_std) + y_train_mean\n",
    "    yhat_train = (yhat_train * y_train_std.values) + y_train_mean.values\n",
    "    y_test = (y_test * y_train_std ) + y_train_mean\n",
    "    yhat_test = (yhat_test * y_train_std.values) + y_train_mean.values\n",
    "\n",
    "    # Reshape if necessary\n",
    "    y_train = y_train.values.reshape(-1)\n",
    "    y_test = y_test.values.reshape(-1)\n",
    "\n",
    "    # Unstandardize residuals for the training and testing datasets\n",
    "    y_train_residuals = y_train - yhat_train\n",
    "    y_test_residuals = y_test - yhat_test\n",
    "\n",
    "    return y_train, y_test, yhat_train, yhat_test, y_train_residuals, y_test_residuals"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def create_JSON_file(X_train, y_train, y_test, yhat_train, yhat_test, y_train_residuals, y_test_residuals, rmse_train, rmse_test, rmse_train, rmse_test, independent_variables, dependent_variables, standardize, tolerance=2):       \n",
    "    \"\"\"Create a .json file of the machine learning results\"\"\"\n",
    "    # Create a dictionary of the machine learning results\n",
    "    data = dict()\n",
    "    data[\"Independent Variables\"] = independent_variables\n",
    "    data[\"Dependent Variables\"] = dependent_variables\n",
    "    data[\"RMSE\"] = {}\n",
    "    data[\"RMSE\"][\"train\"] = [rmse_train]\n",
    "    data[\"RMSE\"][\"test\"] = [rmse_test]\n",
    "    data[\"Mean\"] = {}\n",
    "    data[\"Mean\"][\"X_train\"] = standardize[\"mean\"][\"X_train\"]\n",
    "    data[\"Mean\"][\"y_train\"] = list(standardize[\"mean\"][\"y_train\"])\n",
    "    data[\"Standard Deviation\"] = {}\n",
    "    data[\"Standard Deviation\"][\"X_train\"] = standardize[\"std\"][\"X_train\"]\n",
    "    data[\"Standard Deviation\"][\"y_train\"] = list(standardize[\"std\"][\"y_train\"])\n",
    "    data[\"Fitted\"] = {}\n",
    "    data[\"Fitted\"][\"train\"] = yhat_train.round(tolerance).tolist()\n",
    "    data[\"Fitted\"][\"test\"] = yhat_test.round(tolerance).tolist()\n",
    "    data[\"Residuals\"] = {}\n",
    "    data[\"Residuals\"][\"train\"] = y_train_residuals.round(tolerance).tolist()\n",
    "    data[\"Residuals\"][\"test\"] = y_test_residuals.round(tolerance).tolist()\n",
    "    \n",
    "    # Write the data to a JSON File\n",
    "    location = data[\"MODEL\"][\"output_file\"]\n",
    "    with open(location, \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "        f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def save_model(model):\n",
    "    \"\"\"Save the model to disk\"\"\"\n",
    "    import pickle\n",
    "    filename = data[\"MODEL\"][\"model_serialization_file\"]\n",
    "    pickle.dump(model, open(filename, 'wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def save_standardization(standardize):\n",
    "    \"\"\"Save the standardization information\"\"\"\n",
    "    # Write the data to a JSON File\n",
    "    location = data[\"MODEL\"][\"standardization_file\"]\n",
    "    with open(location, \"w\") as f:\n",
    "        json.dump(standardize, f)\n",
    "        f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def build_model():\n",
    "    # Retrieve Data\n",
    "    X_train = pd.read_csv('data/X_train.csv', index_col=0)\n",
    "    X_test = pd.read_csv('data/X_test.csv', index_col=0)\n",
    "    y_train = pd.read_csv('data/y_train.csv', index_col=0)\n",
    "    y_test = pd.read_csv('data/y_test.csv', index_col=0)\n",
    "    independent_variables = list(X_train.columns)\n",
    "    dependent_variables = list(y_train.columns)\n",
    "    \n",
    "    # Standardize the data\n",
    "    X_train, X_test, y_train, y_test, standardize = standardize_mean_normalization(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Create model\n",
    "    model = create_model(X_train, y_train)\n",
    "    \n",
    "    # Determine yhat, residuals, and RMSE of training and testing datasets\n",
    "    yhat_train, yhat_test, y_train_residuals, y_test_residuals, rmse_train, rmse_test = get_fitted_residuals_RMSE_values(model, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Unstandardize the data\n",
    "    y_train, y_test, yhat_train, yhat_test, y_train_residuals, y_test_residuals = unstandardize_mean_normalization(y_train, y_test, yhat_train, yhat_test, standardize)\n",
    "    \n",
    "    # Save model\n",
    "    save_model(model)\n",
    "\n",
    "    # Save standardization\n",
    "    save_standardization(standardize)\n",
    "\n",
    "    # Generate JSON file of results\n",
    "    create_JSON_file(X_train, y_train, y_test, yhat_train, yhat_test, y_train_residuals, y_test_residuals, rmse_train, rmse_test, rmse_train, rmse_test, independent_variables, dependent_variables, standardize, tolerance=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#build_model()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}